from pyspark.sql import SparkSession
from pyspark.ml.classification import GBTClassifier
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import time
if __name__ == "__main__":
    # List of cores to use
    cores_list = [2,4,6,8,10,12]
    target_column="HasDetections"


    # Loop over each core configuration
    for cores in cores_list:
        print(f"Training with {cores} cores...")

        # Define the SparkSession with the specified number of cores
        spark5 = SparkSession.builder \
            .appName("Malware Prediction LR") \
            .config("spark.executor.memory", '12g') \
            .config("spark.driver.maxResultSize", '12g') \
            .config("spark.kryoserializer.buffer.max", '512m') \
            .config("spark.default.parallelism", str(cores)) \
            .getOrCreate()   
            # Initialize evaluators
        binary_evaluator = BinaryClassificationEvaluator(labelCol="HasDetections")
        f1_evaluator = MulticlassClassificationEvaluator(labelCol=target_column, metricName="f1")
        # Read the Parquet file into a DataFrame
        reduced_features_with_target_sdf = spark5.read.parquet("gs://dhrithi-yarn-cluster-bucket/EDAed_data.parquet")


        # Split the data into training set (80%) and test set (20%)
        train_data, test_data = reduced_features_with_target_sdf.randomSplit([0.8, 0.2], seed=42)

        # Define the GBT model
        gbt = GBTClassifier(featuresCol='features', labelCol="HasDetections")

        # Set up the parameter grid
        paramGrid = ParamGridBuilder() \
            .addGrid(gbt.maxDepth, [5,10]) \
            .addGrid(gbt.maxIter, [20, 30]) \
            .build()

        # Set up the cross-validator
        crossval = CrossValidator(estimator=gbt,
                                estimatorParamMaps=paramGrid,
                                evaluator=BinaryClassificationEvaluator(labelCol="HasDetections"),
                                numFolds=3)

        start_time = time.time()  # Start the timer

        # Train the model
        cv_model = crossval.fit(train_data)

        # Make predictions on the test set
        predictions = cv_model.transform(test_data)

        # Evaluate the model using AUC and RMSE
        auc = binary_evaluator.evaluate(predictions)
        f1 = f1_evaluator.evaluate(predictions)

        end_time = time.time()  # Stop the timer
        # Get the number of cores used

        print(f"Cores: {cores}")
        print(f"AUC: {auc}")
        print(f"F1 Score: {f1}")
        print(f"Time taken: {end_time - start_time} seconds\n")
     