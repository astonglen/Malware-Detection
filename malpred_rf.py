from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import RandomForestClassifier

from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator

import time

if __name__ == "__main__":
    spark5 = SparkSession.builder \
    .appName("Malware Prediction LR") \
    .config("spark.executor.memory", '12g') \
    .config("spark.driver.maxResultSize", '12g') \
    .config("spark.kryoserializer.buffer.max", '512m') \
    .getOrCreate()    


    # Read the Parquet file into a DataFrame
    reduced_features_with_target_sdf = spark5.read.parquet("gs://dhrithi-yarn-cluster-bucket/EDAed_data.parquet")
    
    # List of subsample percentages
    subsamples = [1.0, 0.8, 0.6, 0.4, 0.2]
    target_column="HasDetections"

    # Initialize evaluators

    binary_evaluator = BinaryClassificationEvaluator(labelCol=target_column)
    regression_evaluator = RegressionEvaluator(labelCol=target_column)


    # Loop over each subsample
    for subsample in subsamples:
        print(f"Training with {subsample*100}% data...")

        start_time = time.time()  # Start the timer

        # Sample data
        # False indicates that we are not sampling with replacement
        sample_data = reduced_features_with_target_sdf.sample(False, subsample, seed=42)

        # Split the data into training set (80%) and test set (20%)
        train, test = sample_data.randomSplit([0.8, 0.2], seed=42)


        # Train a Random Forest model
        rf = RandomForestClassifier(featuresCol="features", labelCol="HasDetections")
    
  
        # Define the parameter grid for hyperparameter tuning
        paramGrid = (ParamGridBuilder()
             .addGrid(rf.numTrees, [100, 200])
             .addGrid(rf.maxDepth, [5, 10])
             .addGrid(rf.featureSubsetStrategy, ["sqrt"])
             .build())


        # Create a CrossValidator
        crossval = CrossValidator(estimator=rf,
                          estimatorParamMaps=paramGrid,
                          evaluator=BinaryClassificationEvaluator(labelCol=target_column),
                          numFolds=3)  # Number of cross-validation folds

        # Run cross-validation and choose the best model
        cvModel = crossval.fit(train)
    
 
        # Make predictions on the testing data using the best model
        predictions = cvModel.transform(test)

        #Evaluate the model's performance
        auc = binary_evaluator.evaluate(predictions)

        # Calculate F1 score
        multiclass_evaluator = MulticlassClassificationEvaluator(labelCol="HasDetections")
        f1_score = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: "f1"})

        # Calculate precision
        precision = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: "weightedPrecision"})

        # Calculate recall
        recall = multiclass_evaluator.evaluate(predictions, {multiclass_evaluator.metricName: "weightedRecall"})

        
        end_time = time.time()
 
        # Get the number of cores used
        spark_context = spark5.sparkContext
        num_cores = spark_context.defaultParallelism
        app_id = spark_context.applicationId


        print(f"Subsample: {subsample*100}%")

        print(f"AUC: {auc}")
        print(f"F1 Score:", f1_score)   
        print("Recall: ", recall)
        print("Precision: ", precision)
        print(f"Time taken: {end_time - start_time} seconds\n")
        print(f"Number of cores used: {num_cores}")    
        print(f"Spark application ID: {app_id}")


